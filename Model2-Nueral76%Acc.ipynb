{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from keras import utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmain_df = pd.read_csv('./data3/train_data_bagged.csv')\n",
    "testmain_df = pd.read_csv('./data3/test_data_bagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmain_df.rename({'0':'sequence','label':'label'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sequence', 'label'], dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainmain_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainmain_df['sequence'].values\n",
    "y = trainmain_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18080,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 128\n",
    "#embedding_dim = 128\n",
    "max_length = 128\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(X_train, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(X_test, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience= 10, min_delta= 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18080"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "#model.add(Embedding(vocab_size,embedding_dim,input_length = max_length))\n",
    "\n",
    "\n",
    "model.add(Dense(128,  activation='relu',))\n",
    "#model.add(Dropout(0.04))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04)))  #\n",
    "#model.add(Dropout(0.04))\n",
    "\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04)))  #,kernel_regularizer= regularizers.l2(0.05)\n",
    "#model.add(Dropout(0.04))\n",
    "\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04)))  #,kernel_regularizer= regularizers.l2(0.05)\n",
    "#model.add(Dropout(0.04))\n",
    "\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04))) \n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04))) \n",
    "model.add(Dense(64, activation='relu',kernel_regularizer= regularizers.l2(0.04))) \n",
    "\n",
    "#model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "#model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer= regularizers.l2(0.4)))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "362/362 [==============================] - 6s 4ms/step - loss: 14.6400 - acc: 0.5761 - val_loss: 0.7033 - val_acc: 0.6571\n",
      "Epoch 2/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6719 - acc: 0.6952 - val_loss: 0.6248 - val_acc: 0.7281\n",
      "Epoch 3/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6301 - acc: 0.7169 - val_loss: 0.6265 - val_acc: 0.7044\n",
      "Epoch 4/100\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.6214 - acc: 0.7248 - val_loss: 0.6343 - val_acc: 0.6973\n",
      "Epoch 5/100\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.6034 - acc: 0.7377 - val_loss: 0.5925 - val_acc: 0.7440\n",
      "Epoch 6/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6001 - acc: 0.7376 - val_loss: 0.9624 - val_acc: 0.5794\n",
      "Epoch 7/100\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.5939 - acc: 0.7414 - val_loss: 0.5796 - val_acc: 0.7522\n",
      "Epoch 8/100\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5870 - acc: 0.7428 - val_loss: 0.6127 - val_acc: 0.7192\n",
      "Epoch 9/100\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5861 - acc: 0.7436 - val_loss: 0.6219 - val_acc: 0.7113\n",
      "Epoch 10/100\n",
      "362/362 [==============================] - 2s 4ms/step - loss: 0.5768 - acc: 0.7478 - val_loss: 0.5886 - val_acc: 0.7482\n",
      "Epoch 11/100\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.5750 - acc: 0.7527 - val_loss: 0.6567 - val_acc: 0.6967\n",
      "Epoch 12/100\n",
      "362/362 [==============================] - 2s 6ms/step - loss: 0.5774 - acc: 0.7559 - val_loss: 0.6060 - val_acc: 0.7259\n",
      "Epoch 13/100\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.5646 - acc: 0.7611 - val_loss: 0.5887 - val_acc: 0.7427\n",
      "Epoch 14/100\n",
      "362/362 [==============================] - 2s 4ms/step - loss: 0.5641 - acc: 0.7575 - val_loss: 0.6303 - val_acc: 0.7212\n",
      "Epoch 15/100\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5637 - acc: 0.7592 - val_loss: 0.5829 - val_acc: 0.7555\n",
      "Epoch 16/100\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.5573 - acc: 0.7591 - val_loss: 0.6525 - val_acc: 0.6912\n",
      "Epoch 17/100\n",
      "362/362 [==============================] - 2s 5ms/step - loss: 0.5624 - acc: 0.7714 - val_loss: 0.5802 - val_acc: 0.7544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8311060b50>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded, y_train, validation_data=(test_padded,y_test), epochs=100, batch_size=50, callbacks=[early_stop])\n",
    "\n",
    "##batch size = 128\n",
    "##, callbacks=[early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
